{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# loading datasets, index start from 1\nmovies = pd.read_csv('../input/movies.dat', sep='::', header=None, index_col=0)\nmovies.index = np.arange(1, len(movies) + 1)\nusers = pd.read_csv('../input/users.dat', sep='\\t', header=0, index_col=0)\nusers.index = np.arange(1, len(users) + 1)\nratings = pd.read_csv('../input/ratings.dat', sep='::', header=None)\nratings.index = np.arange(1, len(ratings) + 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28cab9d371a9aa0f84901028fb3a916f0f766177"
      },
      "cell_type": "code",
      "source": "# drop some revies of movie not included in dataset\nratings = ratings[ratings[1] < 3883]\nratings[1].max()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad5ee50ee6676540be39109a603129abaae8a682"
      },
      "cell_type": "code",
      "source": "# numbers of items\nnb_users = users.shape[0]\nnb_movies = movies.shape[0]\nnb_ratings = ratings.shape[0]\nprint(\"nb_users: \", nb_users, \" nb_movies: \", nb_movies, \" nb_ratings: \", nb_ratings)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce4375dad1d852960e2da594bb967f80837fdf7a"
      },
      "cell_type": "code",
      "source": "# matrix of rows-users, cols-movies\nuser_ratings = np.zeros((nb_users+1, nb_movies))\n\nfor (idx, record) in ratings.iterrows():\n    user_id = record[0]\n    movie_id = record[1]\n    rating = record[2]\n    user_ratings[user_id, movie_id] = rating\nuser_ratings.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4bf2b313010d94e50432df0d149ee4402602e30"
      },
      "cell_type": "code",
      "source": "# now we split data to train and test\ntrain_set, test_set = train_test_split(user_ratings, test_size=0.2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb59a41a6c374afbca5fe634ea89946f11063c3c"
      },
      "cell_type": "code",
      "source": "# convert numy arreys to pytorch tensors\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntrain_set = torch.Tensor(train_set)\ntest_set = torch.Tensor(test_set)\nprint(device)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5947e3e666d629bd098bbbc6d1dc6ae3ec76351"
      },
      "cell_type": "code",
      "source": "# hiperparameters\nhidden_outer_size = 128\nhidden_inner_size = 128\nbatch_size = 16\nepoch = 50\nlearning_rate = 0.0001\nweight_decay = 0.005",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ab5b760954929fcb6a36028aa6b731ce7288ec9"
      },
      "cell_type": "code",
      "source": "# class of deep autoencoder\nclass DAE(nn.Module):\n    def __init__(self):\n        # init pytorch nn module\n        super(DAE, self).__init__()\n        # 1 parameter is INsize 2 is OUTsize\n        self.fc1 = nn.Linear(nb_movies, hidden_outer_size)\n        self.fc2 = nn.Linear(hidden_outer_size, hidden_inner_size)\n        self.fc3 = nn.Linear(hidden_inner_size, hidden_outer_size)\n        self.fc4 = nn.Linear(hidden_outer_size, nb_movies)\n        self.activation = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.activation(self.fc1(x))\n        x = self.activation(self.fc2(x))\n        x = self.activation(self.fc3(x))\n        x = self.fc4(x)\n        return x\n    \n# this is MSE, but averaged by number of rated movies, not total movies\ndef mse_loss_masked(input, target, num_labels):\n    return torch.div(torch.sum((input - target) ** 2), num_labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "310c1e4136282d5cfbeb9daef856eb5426bc757f"
      },
      "cell_type": "code",
      "source": "dae = DAE()\ndae.to(device)\noptimizer = optim.Adam(dae.parameters(), lr=learning_rate, weight_decay=weight_decay)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ceb96608602a7a6fb0c61855ebedf82a50a779c4"
      },
      "cell_type": "code",
      "source": "# train model\nfor epoch in range(1, epoch+1):\n    train_loss = 0.\n    # Numbers of users who at least rated one movie\n    step = 0\n    row_idx = 0\n    while row_idx < len(train_set):\n        # add an empty dimension for batch size of 1\n        input = train_set[row_idx:row_idx + batch_size,:]\n        # target is copy of the input\n        target = input.clone()\n        # send target and input to device\n        input, target = input.to(device), target.to(device)\n        # we dont calculate grad of target\n        target.require_grad = False\n        # number of movies where rating is not zero\n        num_labels = torch.sum(target > 0)\n        # if user rate at least 1 movie\n        if num_labels > 0:\n            # get predicted ratings for this user\n            output = dae(input)\n            # zero to any movies that user dont rate\n            # we dont wont that in ouer loss calculation\n            output[target == 0] = 0\n            loss = mse_loss_masked(output, target, num_labels)\n            loss_value = loss.detach().cpu().numpy()\n            train_loss = loss_value\n            # backpropagete loss gradient to network\n            loss.backward()\n            # run oprimazer to update waights\n            optimizer.step()\n            step += 1\n        row_idx += batch_size\n    print(\"epoch: \", epoch, ' loss: ', str(train_loss/step))\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c1e0301d6f8cf3dd1094995dba99c31fe86d24b"
      },
      "cell_type": "code",
      "source": "# evaluate model\ntest_loss = 0\nstep = 0\nfor row_idx in range(len(test_set)):\n    # unsqueeze (0) adds batch dimension to the matrix (size of 1)\n    input = test_set[row_idx,:].unsqueeze(0)\n    target = input.clone()\n    target.require_grad = False\n    input, target = input.to(device), target.to(device)\n    num_labels = torch.sum(target > 0)\n    if num_labels > 0:\n        step += 1\n        output = dae(input)\n        output[target == 0] = 0\n        loss = mse_loss_masked(output, target, num_labels)\n        loss_value = loss.detach().cpu().numpy()\n        test_loss += loss_value\nprint(\"test loss: \", str(test_loss / step))",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "test loss:  1.6341499020187593\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0f5c16aa91994bd2bfb9dd00d3fe9d51dd09db7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "871d23f7f24bed0ac7093bcba7996d5d52b51c08"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00b008a6e08eed67103cfca31eb4d7ae37f2b82c"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c758f690a5b05af6ea0156753cfb40b7f6ffa8d5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64feea5a0d527d5e8168f1628d999f33fba0ffb3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b2e35ee2021d88f6be3b01b168ee858a00be296"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73ca012fcbbb2172e46bc7375acdaf2d602b5020"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd3cf4f4812fe5ad7cd7d3afd08293a2927e584e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e28d1a37f4e4327b5aac56bf1d31fca684139ca7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0bf140e9d05551475faf725974330f760cbe9420"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54ce7283f6f394528be6a0b15a418baf4bc257cd"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}